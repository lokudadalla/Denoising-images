# Denoising-images
denoising images using dental image dataset

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
   
</head>
<body>
    <div class="container">
        <h1>Denoising Grayscale Images Using U-Net</h1>
        <p>This project focuses on using a U-Net convolutional neural network to denoise grayscale dental images. The workflow involves several key steps: loading the dataset, adding synthetic noise, training the U-Net model, and evaluating its performance.</p>

  <h2>Image Loading and Preprocessing</h2>
        <p><strong>Functions for Reading Images:</strong></p>
        <p>1. <strong>read_dental function:</strong></p>
        <ul>
            <li>Uses OpenCV to read images from a specified folder.</li>
            <li>Converts images to grayscale.</li>
            <li>Stores images in a numpy array.</li>
        </ul>
        <p>2. <strong>read_all_datasets function:</strong> Calls <code>read_dental</code> to get the dataset.</p>

   <h2>U-Net Model Definition</h2>
        <p>The <code>unet_model</code> function defines a U-Net architecture. U-Net is a type of convolutional neural network particularly well-suited for image segmentation and denoising tasks due to its symmetric encoder-decoder structure with skip connections. The encoder downsamples the input image while capturing context, and the decoder upsamples it to restore the original size, using skip connections to retain spatial information. This architecture helps in effectively reconstructing denoised images.</p>
        <p>Consists of convolutional and max-pooling layers to downsample the image and capture context. The bottleneck is the deepest part of the network that captures high-level features. Upsampling and convolutional layers are used to reconstruct the image, using skip connections from the encoder to preserve spatial information.</p>

  <img src="path/to/your/noisy_image.jpg" alt="Noisy Image">

   <h2>Training and Evaluation</h2>
        <p>A <code>CNN_denoiser</code> class is defined to manage the U-Net model's training and evaluation. The constructor initializes the model with specified parameters such as batch size, number of epochs, and validation split. The training method trains the model using noisy and clean images, while the evaluation method assesses its performance on the test set, printing the loss and accuracy.</p>

  <img src="path/to/your/noisy_image.jpg" alt="Noisy Image">

   <h2>Adding Noise and Training the Model</h2>
        <p>The main block of the code reads the dataset, resizes the images, and normalizes them. It then splits the dataset into training and test sets, adds Gaussian noise to simulate noisy conditions, and trains the U-Net model using these noisy images. The denoised images generated by the model are plotted for comparison with the noisy inputs.</p>

   <p>I trained the U-Net model for only 10 epochs to generate the current denoised images from the noisy images. Below, you can see the comparison between the noisy input images and the denoised output images produced by the model.</p>

   <img src="path/to/your/noisy_image.jpg" alt="Noisy Image">

  <p>While the current results are promising, it's important to note that training the model for more epochs, such as 100 epochs or more, is expected to significantly improve the results. With extended training, the model has more opportunities to learn and fine-tune its weights, leading to higher accuracy and lower loss. Consequently, the denoised images will exhibit better quality, with reduced noise and enhanced details.</p>
    </div>
</body>
</html>
